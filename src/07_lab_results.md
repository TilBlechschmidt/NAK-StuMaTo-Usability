## Ergebnisse des Usabilitytest

<!-- TODO Erklären wie die Informationen ausgewertet wurden? -->

Im Folgenden werden die Erkenntnisse aus dem Usabilitytest näher erläutert. Es haben sich zwei Kategorien von Resultaten ergeben. Zuerst werden Probleme, die bei der Nutzung von einzelnen UI Komponenten aufgetreten sind, genauer beleuchtet. Diese wurden nach Aufgabenstellung gruppiert. Anschließend werden übergreifende Probleme betrachtet, die in verschiedenen Masken aufgetreten sind wo Komponenten wiederverwendet wurden. Dann wird ein Fokus auf die Workflows innerhalb der Anwendung gelegt mit denen die Probanden besondere Schwierigkeiten hatten. Die Probanden werden in den folgenden Unterabschnitten mit Proband 1 bis Proband 4 (abgekürzt mit P1 - P4) identifiziert.

### Probleme mit UI Komponenten

**Einloggen:** Bei der Anmeldung sind keinerlei Schwierigkeiten aufgetreten.

**Wizard:** Nach der Anmeldung wurde ein Wizard angezeigt um das Studentenprofil zu initialisieren. Hier sind mehrere Probleme aufgetreten. P1 versuchte den Studiengang einzutragen, bevor eine Hochschule ausgewählt wurde. Dies ist aktuell nicht möglich, da Studiengänge logisch mit einer Hochschule verknüpft sind. Des Weiteren gab es Schwierigkeiten bei der Benutzung des Zahlen-Feld für das Semester. Hier haben P1 und P2 versucht in das Feld zu klicken und die vorhandene Zahl zu ersetzen, was nicht möglich ist. Diese Problematik tritt in späteren Aufgaben wieder auf. Proband 4 hat versucht den Betreuer als Freitext einzugeben. Das Feld ist jedoch ein nicht optionales Suchfeld bei dem ein Wert aus den Ergebnissen ausgewählt werden muss. Dies führte zu einer unverständlichen Fehlermeldung. Im weiteren Verlauf hat dies Schwierigkeiten verursacht^[Da das Profil nicht initialisiert war und der Proband über die Navigation den Wizard verlassen hat, befand sich die Anwendung in einem inkonsistenten Zustand] und der Versuchsbetreuer musste eingreifen.

**Umschauen:** Diese Aufgabe hat nur geringe Probleme verursacht. P1 und P2 haben relevante Texte (Dashboard & FAQ) nur überflogen obwohl diese im späteren Verlauf relevant waren. Die Verfügbarkeitsdarstellung im Profil hat bei P1 für zusätzliche Verwirrung gesorgt, da unklar war was dieser darstellt und wie man damit interagieren kann. Außerdem ist P3 darauf gestoßen, dass der Zurück-Knopf in einer Daueraufgabe nicht zu dem Tab der Daueraufgaben zurück führt^[Tatsächlich ist es nur eine Weiterleitung zur Einzelaufgaben-Liste, was in späteren Aufgaben weitere Probleme verursacht].

**Profil pflegen:** Die Verfügbarkeitsdarstellung, welche P1 in der vorigen Aufgabe bereits entdeckt hat wurde hier von den restlichen Probanden mit einer ähnlichen Reaktion bemerkt. Bei den Credit-Points gab es Schwierigkeiten mit der Eingabe von Zahlen wie bereits aus dem Wizard bekannt. P4 hat den Speichern-Knopf bei den Credit-Points übersehen und die Seite ohne zu speichern verlassen. Außerdem sprachen P1 und P2 Verwirrung über die Kategorie "Hausarbeiten" aus und waren sich unsicher was darunter fällt. Bei den Studiums-Einstellungen hat P4 versucht den modalen Dialog per Klick außerhalb des Overlays zu schließen, was nicht möglich ist. P2 war bei den wissenschaftlichen Arbeiten unklar was mit Erstellungsdatum gemeint ist, da die meisten Arbeiten über einen Zeitraum erstellt und anschließend bewertet werden. Bei den Kenntnissen gab es mehrere Schwierigkeiten. P1 hat einen Begriff eingetippt und Enter gedrückt bevor die Suchergebnisse geladen haben. Dies führt dazu, dass das Textfeld geleert aber keine Kenntnis eingetragen wurde. Probanden 1 bis 3 haben außerdem kritisiert, dass es keinen Status-Indikator beim Laden von Suchergebnissen oder hinzufügen von Ergebnissen gibt. Alle vier Probanden haben vergessen die Kenntnisse zu speichern nachdem sie hinzugefügt wurden^[Hier ist zusätzlich eine Inkonsistenz aufgefallen: Wird eine Kenntnis hinzugefügt so speichert die Anwendung dies. Dabei werden allerdings sämtliche zuvor getätigten ungesicherten Änderungen verworfen. Ändert man den Kenntnisstand so muss hingegen explizit gespeichert werden.] und das obwohl P1 die Speichern-Schaltfläche mehrfach angeschaut hat. Außerdem haben Probanden 1 und 2 angemerkt, dass es sie verwirrt das die Kenntnisstände nicht von 0% bis 100% sondern von 10% bis 90% gehen. Proband 2 hat versucht eine neue Kenntnis zu erstellen. Dabei war das Format der notwendigen URL unklar, die Fehlermeldung hat jedoch ausreichend Hilfestellung gegeben. Kommen wir nun zu den Einsätzen. Hier wurde das Textfeld für die Aufgabe von den Probanden 1, 2 und 4 als Freitext wahrgenommen. Nachdem die Fehlermeldung auf diesen Trugschluss hingewiesen hat wurde von den drei Probanden angemerkt, dass ihnen die Datenquelle für die Suche unklar ist. Proband 2 hat durch das visuelle Feedback von dem Eingabefeld erwartet, dass mehrere Aufgaben ausgewählt werden können. Weitere Schwierigkeiten hatten die Probanden mit den Eingabefeldern für den Zeitraum des Einsatz. P2 und P4 war unklar, dass der Zeitraum aus der Aufgabe automatisch übernommen wird. Da diese Probanden das Datum vor der Aufgabe eingetragen haben wurden ihre Daten überschrieben. Außerdem sind Probleme mit der Validierung dieser Felder aufgetreten. Die Felder waren durch die Aufgabe auf ein Datum in der Vergangenheit initialisiert worden. Probanden 2 und 4 haben daraufhin das Startdatum angepasst, welches dann nach dem Enddatum lag. Die Anwendung hat daraufhin eine Fehlermeldung ausgegeben und den Wert zurückgesetzt. Dieses Zurücksetzen wurde von beiden Probanden nicht bemerkt.

**Aufgabe aussuchen:** Probanden 1 und 3 haben als Lösungsansatz die Suche verwendet und als Suchbegriff den Standort genutzt. Dabei hat Proband 1 angemerkt, dass die Zugehörigkeit von den Checkboxen zu den Labels bei den Filtern unklar war. Außerdem wurde angemerkt, dass der Status (P1) und das Datum der Aufgabe (P3) nicht in den Suchergebnissen sichtbar ist. Nachdem über die Ergebnisse zu einer Aufgabe navigiert wurde war unklar, wie man zurückkehren kann. Proband 1 hat versucht die Suche erneut durchzuführen, hatte allerdings aufgrund eines fehlenden Buttons im Suchfeld Schwierigkeiten. Proband 3 hat die Zurück-Schaltfläche in der Aufgabe benutzt, welche wie bereits zuvor erwähnt nicht zu der vorigen Seite navigiert. In der Detailansicht von Aufgaben hat Proband 3 nicht wahrgenommen, dass die angegeben Zeitpunkte der "früheste Beginn" bzw. das "späteste Ende" sind. Entsprechend hat dieser Proband keine passende Aufgabe gefunden. Proband 4 war unklar, ob die aufgelisteten Kenntnisse eine Voraussetzung oder während der Aufgabe zu erwerben sind^[P1 hat ähnliches Feedback zu einem späteren Zeitpunkt gegeben].

**Aufgabe in Profil eintragen:** Das zuvor entdeckte Problem mit den Eingabefeldern für die Zeiträume führte hier bei P1 und P4 erneut zu Schwierigkeiten. Die Übernahme des Zeitraums von der Aufgabe wurde von keinem Probanden bemerkt und hat am Ende zu falschen Daten im Profil geführt. Dies führte dazu, dass es bei P1 und P4 eine Überschneidung mit den zuvor eingepflegten Daten gab. Dabei war zunächst unklar, wie diese Situation gelöst werden konnte. Nach einigem probieren und technischen Problemen seitens der Anwendung^[Beim Bearbeiten bestehender Einsätze treten gelegentlich Fehler auf] konnte diese Situation jedoch gelöst werden.

**TFL in Profil eintragen:** Die bereits mehrfach genannten Zahlen-Felder haben bei P1 zu Schwierigkeiten geführt als die Credit-Points eingetragen wurden. Probanden 2 und 3 haben die Credit-Points gar nicht aktualisiert. Keiner der Probanden hat die Transferleistung in der Verfügbarkeitsübersicht eingepflegt.

**TFL in Verfügbarkeit eintragen:** Hier war zunächst unklar wie eine TFL als Einsatz eingetragen werden kann, da die Datengrundlage für das Aufgabe-Feld P1, P2 und P4 unklar war. Nachdem dieses Problem durch Hilfestellung des Interviewer umgangen wurde traten die bereits bekannten Probleme mit der Überschneidung bei P2 und P4 auf. Dies wurde umgangen, indem die  TFL an ein "falsches" Datum verschoben wurde. Dazu in Abschnitt [TODO REF WORKFLOW SECTION] mehr. Die Eingabe des Zeitraums hat erneut bei P3 und P4 zu den bekannten Problemen geführt.

**Idee für Praxisphase eintragen:** Proband 1 hat den Hinzufügen-Knopf in der Aufgabenübersicht als abhängig von dem ausgewählten Tab wahrgenommen (was nicht der Fall ist) und sich gewundert, dass eine erneute Abfrage stattfand. Bei der Eingabe der PT haben P1 und P4 erneut Probleme mit dem Zahlen-Feld gehabt. P1 hatte zusätzlich das bekannte Problem mit der Validierung des Zeitraums. Das Eingabefeld für die vorangegangene Aufgabe wurde von P1 und P4 als Freitext wahrgenommen und von P2 ignoriert. P4 hat zusätzlich den Aufwand und Ansprechpartner ignoriert worauf durch eine Fehlermeldung hingewiesen wurde, welche hilfreich war.

Zusammenfassend waren Nutzereingaben das Hauptproblem. Zahlen-Felder haben bei jedem Teilnehmer zu Schwierigkeiten geführt, Textfelder mit Suchfunktionen wurden als Freitext-Felder wahrgenommen und Zeitraum-Felder haben zu unbemerkt inkorrekten Daten geführt. Des Weiteren wurde häufig nicht gespeichert obwohl dies stellenweise notwendig ist.

### Probleme mit Workflows

Die gestellten Aufgaben haben einige kritische Workflows in der Anwendung geprüft. Bei diesen sind mehrere Probleme aufgefallen, die im Folgenden näher beleuchtet werden.

**Einsatz eintragen:** Der erste Ansatz von den Probanden bestand daraus auf das Profil zu navigieren. Dort wurde dann von allen die Verfügbarkeitsübersicht angeschaut, welche sich jedoch nicht direkt modifizieren lässt. Teilnehmer haben explizit erwähnt, dass ihnen unklar ist was diese Komponente darstellt und wie sie sich anpassen lässt. Anschließend sind alle Probanden zu der Liste von Einsätzen weiter unten navigiert. Dort traten weitere Hürden auf. Es war zunächst unklar was als Datengrundlage für das Aufgaben-Feld fungiert. Nach einigem probieren wurde den Probanden klar, dass eine bestehende Aufgabe verlinkt werden muss. Dort ist der Ablauf jedoch relativ kompliziert, da Aufgaben nur per Titel gesucht und nicht direkt aus der Aufgabenliste in das Profil übernommen werden können. Außerdem gab es einige Probleme mit den Eingabefeldern, welche das Eintragen der Daten erschwert haben. Diese sind in dem vorigen Abschnitt aufgelistet.

**TFL eintragen:** Der Prozess eine Transferleistung in das System einzutragen gestaltete sich sehr schwierig für die Probanden. Zu allererst muss die Arbeit in dem eigenen Profil unter wissenschaftliche Arbeiten hochgeladen werden. Anschließend müssen die Credit-Points aktualisiert werden. Damit steht die TFL allerdings noch nicht in der Verfügbarkeitsübersicht. Um dies zu erreichen muss eine neue Aufgabe erstellt werden, die den Titel der TFL trägt und bereits den Zustand abgeschlossen hat. Dann kann ein Einsatz in dem Profil erstellt werden bei dem erneut der Zeitraum eingetragen und dann die Aufgabe referenziert werden muss. Dabei muss allerdings beachtet werden, dass dieser Eintrag sich nicht mit dem vermutlich im gleichen Zeitraum zutreffenden Einsatz der Praxisphase überschneidet. Dieser gesamte Prozess ist dabei nicht nur außerordentlich komplex und schwierig^[Keiner der Teilnehmer hat diesen von alleine durchlaufen und auch auf Nachfrage hat nur P3 diesen abschlossen, jedoch die Credit-Points vergessen] sondern erzeugt auch eine stark redundante Datenhaltung.
Im abschließenden Interview wurde der Prozess des Eintragen der Transferleitung häufig kritisiert. Er wurde von drei Probanden als zu komplex beschrieben (P1,P2,P4). Dabei wurde sich gewünscht, dass sich Transferleistungen und Praxiseinsätze überschneiden können sollten (P3). Zudem sollen sich auch Theoriephasen und die Bearbeitung einer Transferleistung überschneiden können (P3). Im Usabilitytest sind die Probanden an einer Inputvalidierung gescheitert, die das Eintragen einer Aufgabe verhindert, wenn sich diese mit einer anderen Aufgabe überlappt. Dies hatte zur Folge, dass drei Probanden invalide Daten für die Bearbeitung der Transferleistung angaben. Zudem wurde der im FAQ beschriebene Prozess eine Transferleistung als abgeschlossene Aufgabe zu behandeln kritisiert, da nicht alle Attribute einer Aufgabe auf eine Transferleistung anzuwenden sind (P2). Das bloße Anlegen der Transfersleistung sollte genügen und sofort in den Kalender mit aufgenommen werden (P2). Dabei war das Datum, das bei der Transferleistung eingetragen war, nicht klar, wofür es stehen sollte (P2).

**Student suchen:** Der Workflow um den es sich hier befasst sich damit einen Studenten für eine Zusammenarbeit an einer Aufgabe zu finden. Um dieses Problem zu lösen gab es drei verschiedene Ansätze: Zuerst haben P2 und P4 die geforderten Kenntnisse in die Suchfunktion eingegeben. Da diese jedoch nur die Kenntnisse in Aufgaben durchsucht und nicht in Studenten sind hierbei keine relevanten Ergebnisse geliefert worden. Der zweite Ansatz umfasste eine manuelle Suche nach passenden Studenten. Dies wurde ebenfalls von P2 und P4 durchgeführt. Dabei stellte sich relativ schnell heraus, dass es keine einfache Möglichkeit gibt die relevanten Informationen auf einen Blick zu erlangen. Stattdessen musste mit vielen Klicks das Profil von jedem Studenten durchgeschaut werden. Dabei war teilweise unklar ob ein gegebener Student in dem geforderten Zeitraum überhaupt verfügbar sein wird (P4). Das Panel "Allgemeine Informationen" in dem Profil wurde dabei nie betrachtet. Der letzte Ansatz, welcher schlussendlich von allen Teilnehmern durchgeführt wurde, ist das Erstellen einer Aufgabe. Auch hier gab es einige Probleme wie z.B. übersehene und nicht optionale Eingabefelder (Ansprechpartner bei P2 und P4, Aufwand bei P4), Textfelder mit unklarer Suchfunktion (P1, P4) oder bekannte Probleme mit Datums- und Zahlen-Feldern. Außerdem stellte sich über verbales Feedback heraus, dass für fremde/neue Anwender (P4) das Konzept von Aufgaben und der Zuweisung von Studenten unklar ist. Hier wurde versucht ein Student, welcher zuvor durch manuelle Suche gefunden wurde, explizit einer Aufgabe zuzuordnen.
In der Nachbetrachtung wurde an diesem Prozess kritisiert, dass es zu aufwändig ist, Studenten zu suchen. Dies hätte zu viele Klicks auf die einzelnen Studentenprofile erfordert (P2). Dabei wurde sich gewünscht, dass sich die Studenten besser sortieren und filtern lassen (P1, P4).

### Gesamteindruck und Verbesserungsvorschläge

In der Nachbetrachtung des Usabilitytests sind die Probanden nach ihrem Gesamteindruck und nach Verbesserungsvorschlägen befragt worden. Diese Daten sind sehr relevant, da die Punkte, die dort genannt werden, die höchste Priorität für den Nutzer haben. Im folgenden werden nur diejenigen Verbesserungsvorschläge aufgenommen, die einen nicht nur ästehtischer Natur sind, sondern eine Prozess betreffen, und welche schon Funktionalitäten betreffen, die schon existieren. Neue Funktionalitäten als Verbesserungsvorschlag werden daher ignoriert. 

Im Gesamteindruck wurde positiv beurteilt, dass StuMaTo als übersichtlich (P2,P1) und gut bedienbar (P2) sind. Die Dialoge sind einfach gehalten und alle Informationen gut verfügbar (P1). Den Gesamteindruck trüben lange Wartezeiten (P3), zu komplizierte Prozesse (P2) und einzelne Bugs (P1). 
Es wurden zwei Hauptprobleme ausgemacht, die Workflows des Eintragens der Transferleistung und das Finden von Studenten. Diese beiden Probleme wurden bereits im Detail analysiert.
Weitere Verbesserungsvorschläge wurden bei dem Bewerben auf eine Aufgabe gewünscht. Hier sollte es mehr Feedback geben, wenn man sich auf eine Aufgabe beworben hat (P2). Dabei soll es zudem möglich sein, über den Umfang einer Aufgabe verhandeln zu können und somit die Aufgabe kleinteiliger einteilen zu können (P4). Auch der Unterschied zwischen Einzelaufgaben und Daueraufgaben wurde nicht jedem Nutzer klar (P4). 
Ein weiterer Wunsch ist es, dass Klausurergebnisse in das Profileingetragen werden können. Dabei sollen sich die erlangten CreditPoints automatisch aktualisieren (P4). Die einzelnen Module sollten dabei aufgelistet werden und angehakt werden, wenn diese bestanden worden sind (P4). Somit kann das Eintragen der CreditPoints vereinfacht werden.  

### Reflexion der Methodik

Bezüglich der gewählten Methodik hat sich der Eye Tracker als besonders zielführend herausgestellt. Die Bildschirmaufzeichnungen haben eine signifikante Hilfe bei der Auswertung dargestellt und die Eye-Tracking Daten, welche im Video eingebettet waren, waren gelegentlich hilfreich. Die Heatmap Funktion der Software stellte sich jedoch als unbrauchbar für unsere Zwecke heraus, da bei dem Test ein externer Browser genutzt wurde. Dadurch waren keine Marker in den Daten vorhanden, welche Navigation zwischen Seiten identifizieren und es konnte nicht für Scrolling kompensiert werden. Außerdem stellte sich heraus, dass der Export der Daten teils signifikant länger als die Aufzeichnung dauerte. Zusätzlich hat sich ein Teilnehmer sehr viel vor dem Bildschirm bewegt und entsprechend wiesen die Daten dort starke Lücken auf. In Zukunft sollte explizit darauf hingewiesen werden, dass der Nutzer still sitzen soll.

Die nächste eingesetzte Methodik war der Face Reader. Während der Aufzeichnungen sind mehrfach technische Probleme aufgetreten^[Die Anwendung ist beim Speichern abgestürzt und hat die Projektdatei dabei beschädigt. Außerdem ist die Verbindung zur Webcam mehrfach unterbrochen worden (bis zu dem Punkt wo ein vollständiger Kalt-Start des Rechners und eine Neuinstallation der Treiber notwendig war)], welche einen Großteil der Daten unbrauchbar machten. Die verbleibenden Daten stellten sich ebenfalls als mäßig nützlich heraus. Dies liegt vermutlich an der sehr rudimentären Kalibrierung zu Beginn (um präzisere Daten zu erhalten müsste jeder Teilnehmer einzeln explizit über einen längeren Zeitraum kalibriert werden). Auch hier trat das Problem mit den starken Bewegungen von einem Teilnehmer auf, was dazu führte, dass die Software das Gesicht nicht richtig erkannt hat. Die Daten wurden schlussendlich nicht in die Analyse-Ergebnisse mit eingebunden.

Die externen Videoaufzeichnungen durch die vorhandenen Kameras im Raum wurden ebenfalls verworfen, da auf den Videos keine signifikanten Informationen vorhanden waren. Gestik und Mimik waren entweder nicht vorhanden oder nicht erkennbar bzw. haben keinen nennenswerten Rückschluss auf die Nutzbarkeit der Anwendung gegeben.

Zusätzlich zu den Audioaufzeichnungen durch die externen Kameras wurde eine sekundäre Audioaufzeichnung durchgeführt. Dies stellte sich als sehr nützlich heraus, da die Qualität signifikant besser war und auch unterschwellige Geräusche wie z.B. ein Säufzen des Nutzers hörbar gemacht hat. Diese Aufzeichnungen wurden mit den Videos des Eye Tracker zusammengefasst und dann ausgewertet. Dabei wurden die Notizen des Interviewers referenziert. Die zusätzliche Audio-Spur ermöglichte es eine direkte Verbindung von den Notizen zu dem Bildschirminhalt herzustellen.

Die Interviews nach den Nutzertests sind als sehr positiv zu bewerten. Sie haben nochmal neue Punkte geliefert, wie die Nutzer die Anwendung wahrgenommen haben und welche Probleme sie am meisten gestört haben. So konnte die Schwere der Probleme besser eingeschätzt werden. Zudem war es sinnvoll, die Nutzer nach Verbesserungsvorschlägen zu fragen, da aus ihnen nun Anhaltspunkte generiert wurden, die im kommenden Gestaltungsprozess der Anwendung verwendet werden.
